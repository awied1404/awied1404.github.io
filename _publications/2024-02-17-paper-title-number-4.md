---
title: "Semantic 3D scene segmentation for robotic assembly process execution"
collection: publications
category: conferences
permalink: /publication/2024-02-17-paper-title-number-4
excerpt: 'This paper is about a robot manipulator autonomously exploring a new workspace and segmenting it semantically in order to execute an assembly process'
date: 2023-09-28
venue: 'CASE 2023'
bibtexurl: 'http://awied1404.github.io/files/sem-seg.bib'
paperurl: 'http://awied1404.github.io/files/semantic-scene-segmentation.pdf'
citation: 'A. Wiedholz, S. Wucherer, S. Dietrich and F. Kerber, "Semantic 3D Scene Segmentation for Robotic Assembly Process Execution," 2023 IEEE 19th International Conference on Automation Science and Engineering (CASE), Auckland, New Zealand, 2023, pp. 1-6, doi: 10.1109/CASE56687.2023.10260532.'
---
Adapting robot programmes to changes in the environment is a well-known industry problem, and it is the reason why many tedious tasks are not automated in small and medium-sized enterprises (SMEs). A semantic world model of a robot’s previously unknown environment created from point clouds is one way for these companies to automate assembly tasks that are typically performed by humans. The semantic segmentation of point clouds for robot manipulators or cobots in industrial environments has received little attention due to a lack of suitable datasets. This paper describes a pipeline for creating synthetic point clouds for specific use cases in order to train a model for point cloud semantic segmentation. We show that models trained with our data achieve high per-class accuracy (>90%) for semantic point cloud segmentation on unseen real-world data. Our approach is applicable not only to the 3D camera used in training data generation but also to other depth cameras based on different technologies. The application tested in this work is a industry-related peg-in-thehole process. With our approach the necessity of user assistance during a robot’s commissioning can be reduced to a minimum.
